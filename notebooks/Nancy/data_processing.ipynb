{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'fl_open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aca9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                  int64\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "No duplicate rows found.\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75511\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'property_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BeCode_Projects/immo-eliza-cats-analysis/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'property_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dp = DataProcessing(file_path=\u001b[33m'\u001b[39m\u001b[33m../Kristin/sample_data_copy/properties.csv\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# adjust path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst 5 rows after cleaning:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(dp.df.head(\u001b[32m5\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mDataProcessing.process_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.clean_other_numeric_columns()\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.remove_duplicates()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mremove_empty_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.fill_missing()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 134\u001b[39m, in \u001b[36mDataProcessing.remove_empty_rows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m         col_empty = \u001b[38;5;28mself\u001b[39m.df[col].astype(\u001b[38;5;28mstr\u001b[39m).str.strip().eq(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    133\u001b[39m     empty_mask |= col_empty\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m missing_id_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproperty_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isna() | (\u001b[38;5;28mself\u001b[39m.df[\u001b[33m'\u001b[39m\u001b[33mproperty_id\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.strip() == \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# remove rows without property_id\u001b[39;00m\n\u001b[32m    135\u001b[39m num_missing = missing_id_mask.sum()\n\u001b[32m    136\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_missing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m row(s) with missing property_id\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BeCode_Projects/immo-eliza-cats-analysis/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/BeCode_Projects/immo-eliza-cats-analysis/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'property_id'"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecbed189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line (header preview): id,price,property_type,subproperty_type,region,province,locality,zip_code,latitude,longitude,construction_year,total_area_sqm,surface_land_sqm,nbr_frontages,nbr_bedrooms,equipped_kitchen,fl_furnished,fl_open_fire,fl_terrace,terrace_sqm,fl_garden,garden_sqm,fl_swimming_pool,fl_floodzone,state_building,primary_energy_consumption_sqm,epc,heating_type,fl_double_glazing,cadastral_income\n",
      "Using separator: ','\n"
     ]
    }
   ],
   "source": [
    "# safe load: try to detect separator and avoid dtype guess warnings\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../Kristin/sample_data_copy/properties.csv'\n",
    "\n",
    "# peek at first line to detect separator\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    first_line = f.readline().strip()\n",
    "print(\"First line (header preview):\", first_line)\n",
    "\n",
    "# choose separator: use semicolon if present, otherwise comma\n",
    "sep = ';' if ';' in first_line else ','\n",
    "print(\"Using separator:\", repr(sep))\n",
    "\n",
    "# read with low_memory=False to get stable dtypes\n",
    "df = pd.read_csv(file_path, sep=sep, encoding='utf-8', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620aeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new header info:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604530cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 54 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75484\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 65592 empty row(s)\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 9892\n",
      "\n",
      "Filling missing fields...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "          id     price property_type      subproperty_type            region  \\\n",
      "14    599000   1100000         HOUSE                 HOUSE          Wallonia   \n",
      "15  67642000   9200000         HOUSE                 VILLA          Flanders   \n",
      "19  40141000  14950000         HOUSE  EXCEPTIONAL_PROPERTY  Brussels-Capital   \n",
      "29  34389000   1650000         HOUSE                 HOUSE          Wallonia   \n",
      "37  77787000   3000000         HOUSE                 HOUSE          Flanders   \n",
      "\n",
      "         province    locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "14        Hainaut   Charleroi      6010  50.393419   4.469180  ...          0   \n",
      "15  West Flanders      Veurne      8670  51.123406   2.672099  ...          0   \n",
      "19       Brussels    Brussels      1083  50.868082   4.321352  ...          0   \n",
      "29          Liège       Liège      4430  50.656811   5.520998  ...          0   \n",
      "37  East Flanders  Oudenaarde      9660  50.802802   3.769636  ...          0   \n",
      "\n",
      "    garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "14           0                 0             0     TO_RENOVATE   \n",
      "15           0                 0             1            GOOD   \n",
      "19           0                 0             0            GOOD   \n",
      "29           0                 0             0         MISSING   \n",
      "37           0                 0             0         MISSING   \n",
      "\n",
      "    primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
      "14                           386.0    E       FUELOIL                  1   \n",
      "15                           139.0    B           GAS                  1   \n",
      "19                           498.0    G           GAS                  0   \n",
      "29                           295.0    D       FUELOIL                  0   \n",
      "37                           286.0    C           GAS                  1   \n",
      "\n",
      "    cadastral_income  \n",
      "14             535.0  \n",
      "15            1023.0  \n",
      "19            6962.0  \n",
      "29             371.0  \n",
      "37             604.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new empty row removal code:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aefabe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 54 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75484\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all non-id fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75484\n",
      "\n",
      "Filling missing fields...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "         id    price property_type subproperty_type            region  \\\n",
      "0  34221000  2250000     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  4490000         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  3350000     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  5010000         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  9827000     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410   0.000000   0.000000  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0           0                 0             0         MISSING   \n",
      "1           0                 0             0         MISSING   \n",
      "2           0                 0             1          AS_NEW   \n",
      "3           0                 0             1         MISSING   \n",
      "4         142                 0             0          AS_NEW   \n",
      "\n",
      "   primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                           231.0        C           GAS                  1   \n",
      "1                           221.0        C       MISSING                  1   \n",
      "2                             0.0  MISSING           GAS                  0   \n",
      "3                            99.0        A       MISSING                  0   \n",
      "4                            19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
