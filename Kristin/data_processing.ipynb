{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082a3c85",
   "metadata": {},
   "source": [
    "This was the code created for data processing in the scraping project - just copied here for convenience\n",
    "\n",
    "First block is the class and a helper function, \n",
    "second block is to run the code\n",
    "\n",
    "The file_path is to be updated to work within a specific sub-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'fl_open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffc118",
   "metadata": {},
   "source": [
    "In the next block of code, we loaded the existing file to review header names etc, and later adopt those in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbed189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe load: try to detect separator and avoid dtype guess warnings\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../Kristin/sample_data_copy/properties.csv'\n",
    "\n",
    "# peek at first line to detect separator\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    first_line = f.readline().strip()\n",
    "print(\"First line (header preview):\", first_line)\n",
    "\n",
    "# choose separator: use semicolon if present, otherwise comma\n",
    "sep = ';' if ';' in first_line else ','\n",
    "print(\"Using separator:\", repr(sep))\n",
    "\n",
    "# read with low_memory=False to get stable dtypes\n",
    "df = pd.read_csv(file_path, sep=sep, encoding='utf-8', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f3061",
   "metadata": {},
   "source": [
    "Here we updated the old headers and replaced them with the new headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620aeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new header info:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604530cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4b49d",
   "metadata": {},
   "source": [
    "The code is running now, but we noticed many rows were being removed by the script & we doubted this was correct.\n",
    "We reviewed the part of the code that impacted empty row removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new empty row removal code:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ad4eb",
   "metadata": {},
   "source": [
    "Empty row removal now seems to be working - none needed to be removed.\n",
    "We still need to look into values that are coded to MISSING and decide what to do with them.\n",
    "First, we will look at removal of any leading or trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating for removal of leading and training spaces\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.strip_text_columns()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('    ') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601d301",
   "metadata": {},
   "source": [
    "All trailing/leading spaces are now removed, if any.\n",
    "Next, we expect the script to fill missing/empty fields with NaN.\n",
    "Also we want the \"MISSING\" to be replaced with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e9502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating filling missing/empty fields and replacing MISSING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                # Convert 'MISSING' (case-insensitive) to NaN\n",
    "                self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "                # Also ensure empty strings are treated as NaN\n",
    "                if self.df[col].dtype == 'object':\n",
    "                    self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb07b68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 54 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75484\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all non-id fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75484\n",
      "\n",
      "Cleaning missing values: 'MISSING' and converting empty strings to NaN...\n",
      "\n",
      "Stripping leading/trailing spaces from all text columns...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "         id    price property_type subproperty_type            region  \\\n",
      "0  34221000  2250000     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  4490000         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  3350000     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  5010000         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  9827000     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0           0                 0             0             nan   \n",
      "1           0                 0             0             nan   \n",
      "2           0                 0             1          AS_NEW   \n",
      "3           0                 0             1             nan   \n",
      "4         142                 0             0          AS_NEW   \n",
      "\n",
      "   primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
      "0                           231.0    C           GAS                  1   \n",
      "1                           221.0    C           nan                  1   \n",
      "2                             NaN  nan           GAS                  0   \n",
      "3                            99.0    A           nan                  0   \n",
      "4                            19.0   A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217032e",
   "metadata": {},
   "source": [
    "2 items remain to be fixed:\n",
    "- construction_year is float and should be integer\n",
    "- equipped_kitchen has been updated to show a flag and should not have (the data is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6148744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating float for construction_year to integer\n",
    "# Updating to not transform equipped_kitchen into a flag\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages', 'construction_year']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                # Convert 'MISSING' (case-insensitive) to NaN\n",
    "                self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "                # Also ensure empty strings are treated as NaN\n",
    "                if self.df[col].dtype == 'object':\n",
    "                    self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69f0d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 14 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75504\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all non-id fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75504\n",
      "\n",
      "Cleaning missing values: 'MISSING' and converting empty strings to NaN...\n",
      "\n",
      "Stripping leading/trailing spaces from all text columns...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "         id    price property_type subproperty_type            region  \\\n",
      "0  34221000  2250000     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  4490000         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  3350000     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  5010000         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  9827000     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0           0                 0             0             nan   \n",
      "1           0                 0             0             nan   \n",
      "2           0                 0             1          AS_NEW   \n",
      "3           0                 0             1             nan   \n",
      "4         142                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0    C           GAS                  1   \n",
      "1                          221.0    C           nan                  1   \n",
      "2                            NaN  nan           GAS                  0   \n",
      "3                           99.0    A           nan                  0   \n",
      "4                           19.0   A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa41aa7",
   "metadata": {},
   "source": [
    "UPDATES FOR THE SWIMMING POOL PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b354abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "\n",
    "    def convert_yes_no_columns(self):\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'open_fire']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages', 'construction_year']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                # Convert 'MISSING' (case-insensitive) to NaN\n",
    "                self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "                # Also ensure empty strings are treated as NaN\n",
    "                if self.df[col].dtype == 'object':\n",
    "                    self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c339a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 14 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75504\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all non-id fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75504\n",
      "\n",
      "Cleaning missing values: 'MISSING' and converting empty strings to NaN...\n",
      "\n",
      "Stripping leading/trailing spaces from all text columns...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "         id    price property_type subproperty_type            region  \\\n",
      "0  34221000  2250000     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  4490000         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  3350000     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  5010000         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  9827000     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0           0                 0             0             nan   \n",
      "1           0                 0             0             nan   \n",
      "2           0                 0             1          AS_NEW   \n",
      "3           0                 0             1             nan   \n",
      "4         142                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0    C           GAS                  1   \n",
      "1                          221.0    C           nan                  1   \n",
      "2                            NaN  nan           GAS                  0   \n",
      "3                           99.0    A           nan                  0   \n",
      "4                           19.0   A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
