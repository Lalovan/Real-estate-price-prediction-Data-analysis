{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082a3c85",
   "metadata": {},
   "source": [
    "This was the code created for data processing in the scraping project - just copied here for convenience\n",
    "\n",
    "First block is the class and a helper function, \n",
    "second block is to run the code\n",
    "\n",
    "The file_path is to be updated to work within a specific sub-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'fl_open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffc118",
   "metadata": {},
   "source": [
    "In the next block of code, we loaded the existing file to review header names etc, and later adopt those in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbed189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe load: try to detect separator and avoid dtype guess warnings\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../Kristin/sample_data_copy/properties.csv'\n",
    "\n",
    "# peek at first line to detect separator\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    first_line = f.readline().strip()\n",
    "print(\"First line (header preview):\", first_line)\n",
    "\n",
    "# choose separator: use semicolon if present, otherwise comma\n",
    "sep = ';' if ';' in first_line else ','\n",
    "print(\"Using separator:\", repr(sep))\n",
    "\n",
    "# read with low_memory=False to get stable dtypes\n",
    "df = pd.read_csv(file_path, sep=sep, encoding='utf-8', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f3061",
   "metadata": {},
   "source": [
    "Here we updated the old headers and replaced them with the new headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620aeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new header info:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        empty_mask = pd.Series(False, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('')\n",
    "            empty_mask |= col_empty\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all other fields empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} empty row(s)\")\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604530cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4b49d",
   "metadata": {},
   "source": [
    "The code is running now, but we noticed many rows were being removed by the script & we doubted this was correct.\n",
    "We reviewed the part of the code that impacted empty row removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating code with new empty row removal code:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ad4eb",
   "metadata": {},
   "source": [
    "Empty row removal now seems to be working - none needed to be removed.\n",
    "We still need to look into values that are coded to MISSING and decide what to do with them.\n",
    "First, we will look at removal of any leading or trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating for removal of leading and training spaces\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.strip_text_columns()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "           if col != 'id':\n",
    "                if self.df[col].dtype in [int, float]:\n",
    "                    self.df[col] = self.df[col].fillna(0)\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601d301",
   "metadata": {},
   "source": [
    "All trailing/leading spaces are now removed, if any.\n",
    "Next, we expect the script to fill missing/empty fields with NaN. \n",
    "Also we want the \"MISSING\" to be replaced with NaN.\n",
    "\n",
    "THE CODE BELOW IS WORK IN PROGRESS, SO NOT YET WORKING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating filling missing/empty fields and replacing MISSING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # id\n",
    "    # locality\n",
    "    # zip_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # subproperty_type\n",
    "    # nbr_bedrooms\n",
    "    # total_area_sqm: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # fl_furnished\n",
    "    # fl_open_fire\n",
    "    # terrace_sqm - remove possible units m2\n",
    "    # garden_sqm - remove possible units m2\n",
    "    # nbr_frontages\n",
    "    # fl_swimming_pool\n",
    "    # state_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                # Convert 'MISSING' (case-insensitive) to NaN\n",
    "                self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "                # Also ensure empty strings are treated as NaN\n",
    "                if self.df[col].dtype == 'object':\n",
    "                    self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
