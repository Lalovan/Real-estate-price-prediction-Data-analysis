{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4caeeb",
   "metadata": {},
   "source": [
    "This is the final code for cleaning the raw data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e2cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../Kristin/sample_data_copy/properties.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages', 'construction_year']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                # Convert 'MISSING' (case-insensitive) to NaN\n",
    "                self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "                # Also ensure empty strings are treated as NaN\n",
    "                if self.df[col].dtype == 'object':\n",
    "                    self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b699d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                 object\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "Found 14 duplicate row(s)\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75504\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all non-id fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75504\n",
      "\n",
      "Cleaning missing values: 'MISSING' and converting empty strings to NaN...\n",
      "\n",
      "Stripping leading/trailing spaces from all text columns...\n",
      "\n",
      "First 5 rows after cleaning:\n",
      "         id    price property_type subproperty_type            region  \\\n",
      "0  34221000  2250000     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  4490000         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  3350000     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  5010000         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  9827000     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0           0                 0             0             nan   \n",
      "1           0                 0             0             nan   \n",
      "2           0                 0             1          AS_NEW   \n",
      "3           0                 0             1             nan   \n",
      "4         142                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0    C           GAS                  1   \n",
      "1                          221.0    C           nan                  1   \n",
      "2                            NaN  nan           GAS                  0   \n",
      "3                           99.0    A           nan                  0   \n",
      "4                           19.0   A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessing(file_path='../Kristin/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
