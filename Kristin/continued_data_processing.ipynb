{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa41aa7",
   "metadata": {},
   "source": [
    "REVIEWING ALL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False):\n",
    "    \"\"\"\n",
    "    Cleans numeric-like columns:\n",
    "    - removes unwanted characters\n",
    "    - handles European numbers if needed\n",
    "    - converts to numeric with NaN for invalid/missing\n",
    "    - if as_int=True â†’ keeps nullable Int64 dtype (allows <NA>)\n",
    "    \"\"\"\n",
    "\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "\n",
    "    if as_int:\n",
    "        df[column] = df[column].astype(\"Int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# MAIN CLASS\n",
    "\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../data/raw/immoweb_data.csv'):\n",
    "\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','\n",
    "\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes, \"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "        self.numeric_int_columns = [\n",
    "            'nbr_bedrooms',\n",
    "            'nbr_frontages',\n",
    "            'construction_year',\n",
    "            'total_area_sqm',\n",
    "            'terrace_sqm',\n",
    "            'garden_sqm',\n",
    "            'surface_land_sqm',\n",
    "            'cadastral_income'\n",
    "        ]\n",
    "\n",
    "        # Categorical fields where \"MISSING\" must stay unchanged\n",
    "        self.categorical_columns = [\n",
    "            'equipped_kitchen',\n",
    "            'state_building',\n",
    "            'heating_type'\n",
    "        ]\n",
    "\n",
    "    def process_data(self):\n",
    "        self.clean_price()\n",
    "        self.clean_areas()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self):\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    def clean_areas(self):\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[Â²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "\n",
    "        print(\"Cleaning area fields...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self):\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages', 'construction_year']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self):\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "\n",
    "        missing_id_mask = (\n",
    "            self.df['id'].isna() |\n",
    "            (self.df['id'].astype(str).str.strip() == '')\n",
    "        )\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "\n",
    "        if num_empty_rows > 0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self):\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    def clean_missing(self):\n",
    "        for col in self.df.columns:\n",
    "            if col == 'id':\n",
    "                continue\n",
    "\n",
    "            # ðŸ”¥ NEW RULE: do NOT touch \"MISSING\" in specific categorical columns\n",
    "            if col in self.categorical_columns:\n",
    "                continue\n",
    "\n",
    "            # Convert \"MISSING\" to NaN\n",
    "            self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "\n",
    "            # Convert empty strings to NaN\n",
    "            if self.df[col].dtype == 'object':\n",
    "                self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "        print(\"\\nCleaning missing values: converting 'MISSING' and empty strings to NaN (except categorical columns)...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties.csv'):\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as CSV ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../data/raw/immoweb_data.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties.csv') # adjust path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c70d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if all our numerical missing values are correctly represented by NaN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../Kristin/cleaned_properties.csv\")\n",
    "\n",
    "# Select numeric columns based on dtype\n",
    "numeric_cols = df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Re-convert those columns to numeric (just to test)\n",
    "test = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# True if the test version equals the original (NaN matches NaN)\n",
    "all_clean = test.equals(df[numeric_cols])\n",
    "\n",
    "all_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE ADDED TO THE CLEANING FILE: creating EPC categorization across regions, via creating groups \"excellent\", \"good\", \"poor\", \"bad\"\n",
    "\n",
    "# Defining mapping rules for each region\n",
    "\n",
    "epc_mapping = {\n",
    "    \"Flanders\": {\n",
    "        \"A+\": \"excellent\",\n",
    "        \"A\": \"excellent\",\n",
    "        \"B\": \"good\",\n",
    "        \"C\": \"poor\",\n",
    "        \"D\": \"poor\",\n",
    "        \"E\": \"bad\",\n",
    "        \"F\": \"bad\"\n",
    "    },\n",
    "    \n",
    "    \"Brussels-Capital\": {\n",
    "        \"A\": \"excellent\",\n",
    "        \"B\": \"good\",\n",
    "        \"C\": \"good\",\n",
    "        \"D\": \"poor\",\n",
    "        \"E\": \"poor\",\n",
    "        \"F\": \"bad\",\n",
    "        \"G\": \"bad\"\n",
    "    },\n",
    "    \n",
    "    \"Wallonia\": {\n",
    "        \"A++\": \"excellent\",\n",
    "        \"A+\": \"excellent\",\n",
    "        \"A\": \"good\",\n",
    "        \"B\": \"good\",\n",
    "        \"C\": \"poor\",\n",
    "        \"D\": \"poor\",\n",
    "        \"E\": \"poor\",\n",
    "        \"F\": \"bad\",\n",
    "        \"G\": \"bad\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function that uses the rule on region\n",
    "\n",
    "def recode_epc(row):\n",
    "    region = row['region']\n",
    "    epc = row['epc']\n",
    "\n",
    "    if pd.isna(region) or pd.isna(epc):\n",
    "        return np.nan\n",
    "    \n",
    "    region_rules = epc_mapping.get(region)\n",
    "\n",
    "    if region_rules is None:\n",
    "        return np.nan\n",
    "    \n",
    "    return region_rules.get(epc, np.nan)\n",
    "\n",
    "df['epc_group'] = df.apply(recode_epc, axis =1)\n",
    "df = df.drop(columns=['epc'])\n",
    "df = df.rename(columns={'epc_group': 'epc'})\n",
    "df['epc'].value_counts(dropna=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
