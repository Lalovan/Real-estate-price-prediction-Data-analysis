{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c76531",
   "metadata": {},
   "source": [
    "In this notebook I will be re-processing the raw data to convert any missing values, or MISSING to -1 instead of NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HELPER FUNCTION\n",
    "def clean_numeric_column(df, column, pattern='[^\\\\d.,]', as_int=False, is_price=False): \n",
    "    # method to clean a column by removing all unwanted characters like currencies,\n",
    "    # normalize European number format\n",
    "    # then converting the cleaned string to integers\n",
    "    # id should not go through this function, as it is expected to be a combination of letters and numbers\n",
    "    # create a temporary cleaned string version\n",
    "    df[column + '_clean'] = df[column].astype(str).replace(pattern, '', regex=True)\n",
    "\n",
    "    if is_price:\n",
    "        # remove thousands separator dots\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(r'(?<=\\d)\\.(?=\\d)', '', regex=True)\n",
    "        # convert decimal comma to dot\n",
    "        df[column + '_clean'] = df[column + '_clean'].str.replace(',', '.', regex=False)\n",
    "    # convert cleaned string to numeric\n",
    "    df[column] = pd.to_numeric(df[column + '_clean'], errors='coerce')\n",
    "    # drop the temporary clean column\n",
    "    df.drop(columns=[column + '_clean'], inplace=True)\n",
    "    if as_int:\n",
    "        df[column] = df[column].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../data/raw/immoweb_data.csv'):\n",
    "        # path updated with raw data file <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.clean_missing()\n",
    "        self.strip_text_columns()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    def clean_areas(self): # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "            print(\"Cleaning area fields...\")\n",
    "  \n",
    "    def convert_yes_no_columns(self): # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['nbr_bedrooms', 'nbr_frontages', 'construction_year']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method toemove duplicates based on all columns except id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self): # method to remove rows where id is missing or all other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        # identify rows where all non-id columns are empty\n",
    "        # for numeric columns check NaN, for others, check empty string after stripping\n",
    "        empty_mask = pd.Series(True, index=self.df.index)\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_empty = self.df[col].isna()\n",
    "            else:\n",
    "                col_empty = self.df[col].astype(str).str.strip().eq('') | self.df[col].isna()\n",
    "            empty_mask &= col_empty\n",
    "        \n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '') # remove rows without id\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask] # drop rows with missing id\n",
    "\n",
    "        rows_to_drop = self.df[empty_mask].index # remove rows where all non-id fields are empty\n",
    "        num_empty_rows = len(rows_to_drop)\n",
    "        print(f\"Found {num_empty_rows} row(s) where all non-id fields are empty\")\n",
    "        if num_empty_rows >0:\n",
    "            print(\"Preview of up to 10 rows to be removed (by id):\")\n",
    "            display(self.df.loc[rows_to_drop[:10], :])  # this will print the first 10 rows to be removed\n",
    "\n",
    "        self.df.drop(index=rows_to_drop, inplace=True)\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def strip_text_columns(self): # strip leading and trailing spaces from text\n",
    "        text_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in text_cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip()\n",
    "        print(\"\\nStripping leading/trailing spaces from all text columns...\")\n",
    "\n",
    "    # def clean_missing(self): # method to clean any \"MISSING\" string with NaN and ensure missing fields remain NaN\n",
    "    #     for col in self.df.columns:\n",
    "    #         if col != 'id':\n",
    "    #             # Convert 'MISSING' (case-insensitive) to NaN\n",
    "    #             self.df[col] = self.df[col].replace(r'(?i)^MISSING$', np.nan, regex=True)\n",
    "    #             # Also ensure empty strings are treated as NaN\n",
    "    #             if self.df[col].dtype == 'object':\n",
    "    #                 self.df[col] = self.df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    #     print(\"\\nCleaning missing values: 'MISSING' and converting empty strings to NaN...\")\n",
    "\n",
    "# NEW CLEAN_MISSING FUNCTION TO REPLACE MISSING OR EMPTY WITH -1\n",
    "    def clean_missing(self): # Convert missing values ('MISSING' or empty strings) to -1 for all columns except 'id'.\n",
    "        for col in self.df.columns:\n",
    "            if col == 'id':\n",
    "                continue\n",
    "            # Replace 'MISSING' (case-insensitive) with -1\n",
    "            self.df[col] = self.df[col].replace(r'(?i)^MISSING$', -1, regex=True)\n",
    "            # Replace empty strings with -1\n",
    "            self.df[col] = self.df[col].replace(r'^\\s*$', -1, regex=True)\n",
    "            # If column is numeric, ensure type stays numeric\n",
    "            if self.df[col].dtype in [int, float, 'float64', 'int64']:\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce').fillna(-1).astype(int)\n",
    "        print(\"\\nCleaning missing values: all 'MISSING' and empty strings replaced with -1...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../Kristin/cleaned_properties_-1.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc95cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessing(file_path='../data/raw/immoweb_data.csv')  # adjust path\n",
    "dp.process_data()\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(dp.df.head(5))\n",
    "dp.save_to_csv('../Kristin/cleaned_properties_-1.csv') # adjust path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
