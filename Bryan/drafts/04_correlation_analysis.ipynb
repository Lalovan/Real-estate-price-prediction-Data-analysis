{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4238cef",
   "metadata": {},
   "source": [
    "*How many qualitative and quantitative variables are there? What are appropiate visuals for quantitative vs qualitative data? What are appropiate measures for correlations when dealing with qualitative and quantitative variables?\n",
    "\n",
    "What is the correlation between the variables and the price? Why do you think some variables are more correlated than others?\n",
    "\n",
    "How are the variables themselves correlated to each other? Can you find groups of variables that are correlated together?*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def log_transform_column(df: pd.DataFrame, column_name: str, new_col_name: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies the natural log transformation (log(1+x)) to a specified column\n",
    "    and adds it as a new column to the DataFrame.\n",
    "\n",
    "    Log transformation is primarily used for features with a high positive skew\n",
    "    (like price or area) to make the distribution more normal.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame.\n",
    "    column_name : str\n",
    "        The name of the column to be transformed (e.g., 'price').\n",
    "    new_col_name : str, optional\n",
    "        The name of the new log-transformed column.\n",
    "        Defaults to f'log_{column_name}'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the new log-transformed column added.\n",
    "    \"\"\"\n",
    "    if new_col_name is None:\n",
    "        new_col_name = f'log_{column_name}'\n",
    "\n",
    "    # 1. Check if the column exists\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # 2. Check for non-positive values (logarithm is undefined for <= 0)\n",
    "    # Since we use log1p, we only check for negative values\n",
    "    if (df[column_name] < 0).any():\n",
    "        print(f\"Warning: Column '{column_name}' contains negative values. \"\n",
    "              \"Applying log transformation to negative numbers is problematic.\")\n",
    "\n",
    "    try:\n",
    "        # 3. Apply the log(1 + x) transformation (log1p)\n",
    "        # We use .copy() to ensure we are operating on a new DataFrame\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # We use .fillna(0) inside log1p to handle any NaN values gracefully\n",
    "        # (they become log(1+0) = 0 in the new column, or NaN if they should remain)\n",
    "        # If NaN should remain NaN after transformation, use .dropna() first or ensure NaNs are skipped.\n",
    "        # Here we apply it directly, NaNs will result in NaNs in the new column.\n",
    "        df_copy[new_col_name] = np.log1p(df_copy[column_name])\n",
    "\n",
    "        print(f\"✅ Successfully created new column '{new_col_name}' using np.log1p.\")\n",
    "        return df_copy\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during log transformation: {e}\")\n",
    "        return df"
   ],
   "id": "57ef47f3a776ea2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Import the clean data file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "file_path = \"cleaned_properties.csv\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    first_line = f.readline()\n",
    "    sep = ';' if ';' in first_line else ','\n",
    "df = pd.read_csv(file_path, sep=sep, low_memory=False)"
   ],
   "id": "da932087ac69cc31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Capping and log transformations\n",
    "\n",
    "df_before = df.copy() #Keeping a copy of data before capping\n",
    "cap_vars = ['price', 'surface_land_sqm', 'total_area_sqm','garden_sqm', 'terrace_sqm', 'nbr_bedrooms', 'nbr_frontages']\n",
    "lower_cap = 0.01\n",
    "upper_cap = 0.99\n",
    "for var in cap_vars:\n",
    "    lower = df[var].quantile(lower_cap)\n",
    "    upper = df[var].quantile(upper_cap)\n",
    "    df[var] = np.where(df[var] < lower, lower,\n",
    "                       np.where(df[var] > upper, upper, df[var]))\n",
    "\n",
    "# Initiating the log transfiormations\n",
    "log_vars = ['price', 'surface_land_sqm', 'total_area_sqm','garden_sqm', 'terrace_sqm']\n",
    "for var in log_vars:\n",
    "    df = log_transform_column(df, var, f\"{var}_log\")\n",
    "df[[f'{v}_log' for v in log_vars]].skew()\n"
   ],
   "id": "8e064392523bfdd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "318d27fa",
   "metadata": {},
   "source": [
    "# Corr between price and continuous (numeric) variables (Correlation Matrix) - Pearson's corr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Numeric vars\n",
    "num_cols = ['price_log', 'total_area_sqm_log', 'surface_land_sqm_log', 'terrace_sqm_log','garden_sqm_log', 'nbr_bedrooms', 'construction_year', 'primary_energy_consumption_sqm','cadastral_income']\n",
    "\n",
    "corr = df[num_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix (numeric variables)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b85083b3",
   "metadata": {},
   "source": [
    "# which regions/ provinces have the highest median prices\n",
    "\n",
    "df.groupby('region')['price'].median().sort_values(ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b16efdf",
   "metadata": {},
   "source": [
    "# Holistic .corr Analysis with Numeric/log-tranformed variables - Pearson's \n",
    "'''\n",
    "Interpretation\n",
    "Pearson r:\n",
    "0.0–0.3 -> weak correlation\n",
    "0.3–0.6 -> moderate correlation\n",
    "0.6–0.9 -> strong correlation\n",
    "0.9+ -> very strong correlation\n",
    "p-value:\n",
    "Small p (<0.05) -> correlation is statistically significant\n",
    "Large p (≥0.05) -> not significant; could be noise\n",
    "'''\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "num_cols = ['price_log', 'total_area_sqm_log', 'surface_land_sqm_log', 'terrace_sqm_log','garden_sqm_log', 'nbr_bedrooms', 'construction_year', 'primary_energy_consumption_sqm', 'cadastral_income','latitude', 'longitude', 'nbr_frontages']\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i, col1 in enumerate(num_cols):\n",
    "    for j, col2 in enumerate(num_cols):\n",
    "        if i <= j:  # avoid repeating pairs\n",
    "            r, p = pearsonr(df[col1].fillna(0), df[col2].fillna(0))  # fill NA safely\n",
    "            rows.append({'Variable 1': col1,'Variable 2': col2,'Pearson r': r,'p-value': p})\n",
    "\n",
    "# Convert to DataFrame\n",
    "corr_table = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by correlation with price\n",
    "price_corr = corr_table[corr_table['Variable 1']=='price_log'].sort_values(by='Pearson r', ascending=False)\n",
    "price_corr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "649907ac",
   "metadata": {},
   "source": [
    "# Inter-numeric-variables correaltions - detect possible multicollinearity in regressions later on\n",
    "\n",
    "corr_matrix = df[num_cols].corr(method='pearson') \n",
    "corr_matrix\n",
    "corr_pairs = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)).stack().reset_index())\n",
    "corr_pairs.columns = ['Variable 1', 'Variable 2', 'Pearson r']\n",
    "corr_pairs = corr_pairs.sort_values(by='Pearson r', ascending=False)\n",
    "corr_pairs\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8952bf7",
   "metadata": {},
   "source": [
    "#Checking the categorical variables for unique values\n",
    "#fl_swimming_pool causing error in ANOVA due to single unique value\n",
    "\n",
    "# for var in cat_vars:\n",
    "#     print(var, df[var].nunique())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11f29b88",
   "metadata": {},
   "source": [
    "# Categorical vs price analysis - ANOVA\n",
    "# F-statistic and p-value indicate whether the categorical variables have significant effects on price\n",
    "# F- statistic: Measures how large the price differences are between categories relative to within-category variation (higher F -> stronger signal -> the variable kilely affects price).\n",
    "# p-value: probability these differences happened by chance\n",
    "# Notes: locality is left out due to granularity; zip_code better used only for clustering and mapping\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example for variable property_type\n",
    "model = ols('price_log ~ C(property_type)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Iterating over all categorical variables\n",
    "cat_vars = ['property_type', 'subproperty_type', 'region', 'province','epc', 'heating_type', 'state_building','fl_swimming_pool','fl_floodzone',\n",
    "    'fl_open_fire', 'fl_terrace', 'fl_garden', 'fl_double_glazing'] #'fl_furnished',\n",
    "anova_results = []\n",
    "\n",
    "for var in cat_vars:\n",
    "    model = ols(f'price_log ~ C({var})', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    F = anova_table['F'].iloc[0]\n",
    "    p = anova_table['PR(>F)'].iloc[0]\n",
    "    anova_results.append({'Variable': var, 'F-statistic': F, 'p-value': p})\n",
    "\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "anova_df = anova_df.sort_values(by='F-statistic', ascending=False)\n",
    "display(anova_df)\n",
    "\n",
    "#Interpretation of Results: \n",
    "# - Prices differ massively across Belgium’s regions - top predictor\n",
    "# - Swimming pool in place - top predictor\n",
    "# - Houses vs apartments have big price differences - storng predictor\n",
    "# - Provincial differences in prices are large - strong predictor\n",
    "# - State of building (good/renovated/to renovate) heavily impacts price - strong predictor\n",
    "# - Subproperty type - important predictor\n",
    "# - [NOT stat significant] Floodzone - important predictor\n",
    "# - [NOT stat significant] Whether a terrace exists significantly impacts price - strong predictor\n",
    "# - Energy efficiency (epc) has medium-strong influence - medium-strong predictor\n",
    "# - [NOT stat significant] Garden - medium predictor\n",
    "# - [NOT stat significant] Heating type - weak-medium predictor\n",
    "# - [NOT stat significant] Double glazing - weak predictor\n",
    "# - [NOT stat significant] Open fire - very weak predictor\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "345c9d16",
   "metadata": {},
   "source": [
    "# Visualization of the ANOVA results\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=anova_df,x=\"F-statistic\",y=\"Variable\",palette=\"viridis\")\n",
    "\n",
    "plt.title(\"ANOVA F-statistics by Categorical Variable\")\n",
    "plt.xlabel(\"F-statistics (effect size)\")\n",
    "plt.ylabel(\"Categorical Variables\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "767a2273",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "def interactive_joint_and_marginal_distributions_plot(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    title: str,\n",
    "    hue: str = \"province\",\n",
    "    marginal_type: str = \"histogram\" # Options: 'histogram', 'violin', 'box', 'rug'\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an INTERACTIVE joint plot with marginal distributions using Plotly Express.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        x_col (str): The column for the x-axis.\n",
    "        y_col (str): The column for the y-axis.\n",
    "        title (str): The plot title.\n",
    "        hue (str): The column to use for coloring points and marginals.\n",
    "        marginal_type (str): The type of plot to use for the marginal distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    plot_df = df.dropna(subset=[x_col, y_col]).copy()\n",
    "\n",
    "    # Use Plotly Express scatter plot with marginal distributions\n",
    "    fig = px.scatter(\n",
    "        plot_df,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        color=hue,\n",
    "        title=title,\n",
    "        opacity=0.6,\n",
    "        # Add marginal plots on top and right\n",
    "        marginal_x=marginal_type,\n",
    "        marginal_y=marginal_type,\n",
    "        # Optimize for large datasets\n",
    "        render_mode='webgl',\n",
    "        # Add original price and area to hover data for inspection\n",
    "        hover_data=['price', 'total_area_sqm', hue]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_font_size=20,\n",
    "        legend_title_text=hue,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    # Update marginal axis labels for clarity\n",
    "    fig.update_xaxes(title_text=f'{x_col} (Marginal {marginal_type} on top)')\n",
    "    fig.update_yaxes(title_text=f'{y_col} (Marginal {marginal_type} on right)')\n",
    "\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "interactive_joint_and_marginal_distributions_plot(\n",
    "    df=df,\n",
    "    x_col=\"total_area_sqm\",\n",
    "    y_col=\"price_log\",\n",
    "    title=\"Interactive Joint Plot: Area vs. LOG-TRANSFORMED Price\",\n",
    "    hue=\"province\",\n",
    "    marginal_type=\"histogram\"\n",
    ")"
   ],
   "id": "5b5683de7f0d9d94",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
