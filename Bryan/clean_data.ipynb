{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleaning data",
   "id": "bc445b4a7cd8fca4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Robust data cleaning!\n",
    "\n",
    "### 1. **Better Type Handling**\n",
    "- Uses `Int64` (nullable integer) instead of to preserve NaN values `int`\n",
    "- Uses `float64` for decimal precision\n",
    "- Properly handles data type conversions\n",
    "\n",
    "### 2. **Comprehensive Data Cleaning**\n",
    "- Handles multiple decimal points\n",
    "- Removes currency symbols (€, $, £, etc.)\n",
    "- Handles European number formats (1.234.567,89)\n",
    "- Removes units (m², sqm, etc.)\n",
    "- Handles various null representations\n",
    "\n",
    "### 3. **Data Validation**\n",
    "- Min/max value constraints\n",
    "- Negative value handling\n",
    "- Outlier detection using IQR method\n",
    "- Comprehensive reporting\n",
    "\n",
    "### 4. **Better Error Handling**\n",
    "- Checks if columns exist\n",
    "- Reports invalid data conversions\n",
    "- Provides detailed statistics\n",
    "\n",
    "### 5. **Production-Ready Features**\n",
    "- Proper documentation\n",
    "- Progress indicators\n",
    "- Data quality checks\n",
    "- Validation summary\n",
    "- File size reporting"
   ],
   "id": "bfdf8bdfe8a8a5cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:50:50.298174Z",
     "start_time": "2025-11-13T10:50:49.265614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ENHANCED HELPER FUNCTIONS\n",
    "def clean_numeric_column(df, column, as_int=False, is_price=False, is_percentage=False,\n",
    "                         allow_negative=False, min_value=None, max_value=None):\n",
    "    \"\"\"\n",
    "    Clean and standardize numeric columns with comprehensive data validation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing the column to clean\n",
    "    column : str\n",
    "        Name of the column to clean\n",
    "    as_int : bool\n",
    "        Convert to integer type (default: False, keeps as float)\n",
    "    is_price : bool\n",
    "        Special handling for price/currency formats (default: False)\n",
    "    is_percentage : bool\n",
    "        Special handling for percentage values (default: False)\n",
    "    allow_negative : bool\n",
    "        Whether to allow negative values (default: False)\n",
    "    min_value : float or None\n",
    "        Minimum acceptable value, values below are set to NaN\n",
    "    max_value : float or None\n",
    "        Maximum acceptable value, values above are set to NaN\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with cleaned numeric column\n",
    "    \"\"\"\n",
    "\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "        return df\n",
    "\n",
    "    # Store original non-null count for reporting\n",
    "    original_non_null = df[column].notna().sum()\n",
    "\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    cleaned_series = df[column].copy()\n",
    "\n",
    "    # Convert to string for cleaning, preserve NaN\n",
    "    cleaned_series = cleaned_series.astype(str)\n",
    "\n",
    "    # Replace common null representations\n",
    "    null_patterns = ['nan', 'none', 'null', 'n/a', 'na', '#n/a', '#value!', '#ref!',\n",
    "                     '<na>', 'missing', 'MISSING', '--', '']\n",
    "    cleaned_series = cleaned_series.replace(null_patterns, np.nan, regex=False)\n",
    "\n",
    "    # deal with multiple empty spaces\n",
    "    cleaned_series = cleaned_series.str.strip()\n",
    "    cleaned_series.replace('', np.nan, inplace=True)\n",
    "\n",
    "    # Skip if all values are NaN\n",
    "    if cleaned_series.isna().all():\n",
    "        df[column] = np.nan\n",
    "        print(f\"  Warning: Column '{column}' contains only null values\")\n",
    "        return df\n",
    "\n",
    "    # Handle percentage values\n",
    "    if is_percentage:\n",
    "        # Convert percentages like \"85%\", \"85 %\", \"0.85\" to decimal\n",
    "        cleaned_series = cleaned_series.str.replace(r'\\s*%\\s*', '', regex=True)\n",
    "        # Check if values are in percentage format (>1) or decimal format (<=1)\n",
    "        temp_numeric = pd.to_numeric(cleaned_series, errors='coerce')\n",
    "        # If most non-null values are > 1, assume they're percentages\n",
    "        if (temp_numeric > 1).sum() > (temp_numeric <= 1).sum():\n",
    "            temp_numeric = temp_numeric / 100\n",
    "        cleaned_series = temp_numeric\n",
    "\n",
    "    # Handle price/currency values\n",
    "    elif is_price:\n",
    "        # Remove currency symbols: €, $, £, ¥, CHF, USD, EUR, etc.\n",
    "        cleaned_series = cleaned_series.str.replace(r'[€$£¥₹₽¢]', '', regex=True)\n",
    "        cleaned_series = cleaned_series.str.replace(r'\\b(USD|EUR|GBP|CHF|CAD|AUD|JPY)\\b', '',\n",
    "                                                   regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "        # Handle European number format: 1.234.567,89 -> 1234567.89\n",
    "        # First, remove thousand separators (dots, spaces, apostrophes)\n",
    "        cleaned_series = cleaned_series.str.replace(r'(?<=\\d)[.\\s\\'\\u202f\\u00a0]+(?=\\d{3})', '', regex=True)\n",
    "\n",
    "        # Convert decimal comma to dot: 123,45 -> 123.45\n",
    "        # But only if it's the last comma (to avoid issues with thousand separators)\n",
    "        cleaned_series = cleaned_series.str.replace(r',(\\d{1,2})$', r'.\\1', regex=True)\n",
    "\n",
    "        # Remove any remaining non-numeric characters except decimal point and minus\n",
    "        cleaned_series = cleaned_series.str.replace(r'[^\\d.\\-]', '', regex=True)\n",
    "\n",
    "    # Handle regular numeric values (areas, counts, etc.)\n",
    "    else:\n",
    "        # Remove units like m², m2, sqm, sq.m, cm, km, etc.\n",
    "        cleaned_series = cleaned_series.str.replace(r'\\s*(m[²2]|sqm?|sq\\.?\\s*m|cm|km|ft²?|square\\s*meters?)\\s*',\n",
    "                                                   '', regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove thousand separators and normalize decimal separators\n",
    "        cleaned_series = cleaned_series.str.replace(r'(?<=\\d)[.\\s\\'\\u202f\\u00a0]+(?=\\d{3})', '', regex=True)\n",
    "        cleaned_series = cleaned_series.str.replace(',', '.', regex=False)\n",
    "\n",
    "        # Remove any remaining non-numeric characters except decimal point and minus\n",
    "        cleaned_series = cleaned_series.str.replace(r'[^\\d.\\-]', '', regex=True)\n",
    "\n",
    "    # Handle multiple decimal points (keep only the last one)\n",
    "    def fix_multiple_decimals(val):\n",
    "        if pd.isna(val) or val == '':\n",
    "            return np.nan\n",
    "        if isinstance(val, str) and val.count('.') > 1:\n",
    "            parts = val.rsplit('.', 1)  # Split at the last decimal point\n",
    "            return parts[0].replace('.', '') + '.' + parts[1]\n",
    "        return val\n",
    "\n",
    "    cleaned_series = cleaned_series.apply(fix_multiple_decimals)\n",
    "\n",
    "    # Convert to numeric, coercing errors to NaN\n",
    "    cleaned_series = pd.to_numeric(cleaned_series, errors='coerce')\n",
    "\n",
    "    # Handle negative values\n",
    "    if not allow_negative:\n",
    "        negative_count = (cleaned_series < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"  Warning: Found {negative_count} negative values in '{column}', setting to NaN\")\n",
    "        cleaned_series = cleaned_series.where(cleaned_series >= 0, np.nan)\n",
    "\n",
    "    # Apply min/max value constraints\n",
    "    if min_value is not None:\n",
    "        out_of_range = (cleaned_series < min_value).sum()\n",
    "        if out_of_range > 0:\n",
    "            print(f\"  Warning: Found {out_of_range} values below minimum ({min_value}) in '{column}'\")\n",
    "        cleaned_series = cleaned_series.where(cleaned_series >= min_value, np.nan)\n",
    "\n",
    "    if max_value is not None:\n",
    "        out_of_range = (cleaned_series > max_value).sum()\n",
    "        if out_of_range > 0:\n",
    "            print(f\"  Warning: Found {out_of_range} values above maximum ({max_value}) in '{column}'\")\n",
    "        cleaned_series = cleaned_series.where(cleaned_series <= max_value, np.nan)\n",
    "\n",
    "    # Convert to appropriate dtype\n",
    "    if as_int:\n",
    "        # Use Int64 (nullable integer) instead of int to preserve NaN\n",
    "        cleaned_series = cleaned_series.astype('Int64')\n",
    "    else:\n",
    "        # Keep as float64 for decimal precision\n",
    "        cleaned_series = cleaned_series.astype('float64')\n",
    "\n",
    "    # Report cleaning results\n",
    "    final_non_null = cleaned_series.notna().sum()\n",
    "    nulls_created = original_non_null - final_non_null\n",
    "    if nulls_created > 0:\n",
    "        print(f\"  Cleaned '{column}': {nulls_created} values converted to null due to invalid data\")\n",
    "\n",
    "    # Assign back to dataframe\n",
    "    df[column] = cleaned_series\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_and_report(df, column, stats=True):\n",
    "    \"\"\"\n",
    "    Validate and report statistics for a cleaned numeric column.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing the column\n",
    "    column : str\n",
    "        Name of the column to validate\n",
    "    stats : bool\n",
    "        Whether to print detailed statistics\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        return\n",
    "\n",
    "    col_data = df[column]\n",
    "\n",
    "    print(f\"\\n--- Statistics for '{column}' ---\")\n",
    "    print(f\"  Total rows: {len(col_data)}\")\n",
    "    print(f\"  Non-null values: {col_data.notna().sum()} ({col_data.notna().sum()/len(col_data)*100:.1f}%)\")\n",
    "    print(f\"  Null values: {col_data.isna().sum()} ({col_data.isna().sum()/len(col_data)*100:.1f}%)\")\n",
    "    print(f\"  Data type: {col_data.dtype}\")\n",
    "\n",
    "    if stats and col_data.notna().any() and (col_data.dtype.kind == 'f' or col_data.dtype.kind == 'i'):\n",
    "        print(f\"  Min: {col_data.min()}\")\n",
    "        print(f\"  Max: {col_data.max()}\")\n",
    "        print(f\"  Mean: {col_data.mean():.2f}\")\n",
    "        print(f\"  Median: {col_data.median():.2f}\")\n",
    "\n",
    "        # Detect potential outliers using IQR method\n",
    "        Q1 = col_data.quantile(0.25)\n",
    "        Q3 = col_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((col_data < (Q1 - 1.5 * IQR)) | (col_data > (Q3 + 1.5 * IQR))).sum()\n",
    "        if outliers > 0:\n",
    "            print(f\"  ⚠️  Potential outliers (IQR method): {outliers} ({outliers/col_data.notna().sum()*100:.1f}%)\")\n",
    "\n"
   ],
   "id": "c56bc88ee187da14",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This class should contain all the functions that helpls us clean the data.",
   "id": "a96040a2d145476b"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T10:50:50.374014Z",
     "start_time": "2025-11-13T10:50:50.340637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# column names copied from models.py to use in this script for reference:\n",
    "    # property_id\n",
    "    # locality_name\n",
    "    # postal_code\n",
    "    # price - remove possible currency\n",
    "    # property_type\n",
    "    # number_of_rooms\n",
    "    # living_area: - remove possible units m2\n",
    "    # equipped_kitchen\n",
    "    # furnished\n",
    "    # open_fire\n",
    "    # terrace_area - remove possible units m2\n",
    "    # garden_area - remove possible units m2\n",
    "    # number_of_facades\n",
    "    # swimming_pool\n",
    "    # state_of_building\n",
    "\n",
    "# MAIN CLASS\n",
    "class DataProcessing:\n",
    "    def __init__(self, file_path='../data/raw/scraped_data.csv'):\n",
    "        # update line of code above with local CSV file path to load data <---\n",
    "        # ensure old df is cleared so a new file will truly be read (and not a cached file)\n",
    "        if hasattr(self, 'df'):\n",
    "            del self.df\n",
    "        # auto-detect separator in CSV file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline()\n",
    "            sep = ';' if ';' in first_line else ','  # choose ';' if present, else ','\n",
    "        # load full csv file\n",
    "        self.df = pd.read_csv(file_path, sep=sep, dtype={\"property_id\": str}, low_memory=False)\n",
    "        print(\"Detected separator:\", repr(sep))\n",
    "        print(\"\\nBefore any cleaning:\")\n",
    "        print(self.df.dtypes,\"\\n\")\n",
    "        print(self.df.head(5))\n",
    "        print(\"\\nNumber of rows raw data loaded:\", len(self.df))\n",
    "\n",
    "    def process_data(self): # main method to process data, further methods detailed below\n",
    "        self.clean_price()\n",
    "        # self.filter_out_type('life sale')\n",
    "        self.clean_areas()\n",
    "        self.convert_yes_no_columns()\n",
    "        self.clean_other_numeric_columns()\n",
    "        self.remove_duplicates()\n",
    "        self.remove_empty_rows()\n",
    "        self.fill_missing()\n",
    "\n",
    "    def clean_price(self): # method to clean the price column\n",
    "        if 'price' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'price', as_int=True, is_price=True)\n",
    "            print(\"Cleaning price fields...\")\n",
    "\n",
    "    # def filter_out_type(self, type_of_sale): # method to remove rows with a specific property type e.g. life sale\n",
    "    #     if 'type_of_sale' in self.df.columns:\n",
    "    #         self.df = self.df[self.df['type_of_sale'].str.lower() != type_of_sale.lower()]\n",
    "    #         print(\"Filtering out life sale property types...\")\n",
    "    #         print(f\"Number of rows left after filtering out life sale property type = {len(self.df)}\")\n",
    "\n",
    "    def clean_areas(self):  # method to clean the area columns\n",
    "        for col in ['total_area_sqm', 'terrace_sqm', 'garden_sqm']:\n",
    "            if col in self.df.columns:\n",
    "                # Remove units like 'm2', 'm²' (case-insensitive)\n",
    "                self.df[col] = self.df[col].astype(str).str.replace(r'\\s*m[²2]', '', regex=True)\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning area fields...\")\n",
    "\n",
    "    def convert_yes_no_columns(self):  # method to convert yes/no to 1/0\n",
    "        yes_no_map = {'yes': 1, 'y': 1, 'no': 0, 'n': 0}\n",
    "        for col in ['fl_furnished', 'equipped_kitchen', 'fl_open_fire', 'fl_swimming_pool']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                    .str.lower()\n",
    "                    .map(yes_no_map)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                )\n",
    "        print(\"Converting Yes/No columns to 1/0 integers...\")\n",
    "\n",
    "    def clean_other_numeric_columns(self): # convert other numeric columns to integers\n",
    "        for col in ['number_of_rooms', 'number_of_facades']:\n",
    "            if col in self.df.columns:\n",
    "                self.df = clean_numeric_column(self.df, col, as_int=True)\n",
    "        print(\"Cleaning other numeric fields...\")\n",
    "\n",
    "    def remove_duplicates(self): # method to remove duplicates based on all columns except property_id\n",
    "        cols_to_check = [col for col in self.df.columns if col != 'property_id']\n",
    "        # Find duplicates\n",
    "        duplicates_mask = self.df.duplicated(subset=cols_to_check, keep=False)\n",
    "        num_duplicates = duplicates_mask.sum()\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"\\nFound {num_duplicates} duplicate row(s)\")\n",
    "            # print(self.df[duplicates_mask].sort_values(by=cols_to_check).head(10)) # showing first 10 duplicates\n",
    "        else:\n",
    "            print(\"\\nNo duplicate rows found.\")\n",
    "        self.df.drop_duplicates(subset=cols_to_check, keep='first', inplace=True)\n",
    "        print(\"Removing duplicates...\")\n",
    "        print(f\"Number of rows left after removing duplicates = {len(self.df)}\")\n",
    "\n",
    "    def remove_empty_rows(self):  # method to remove rows where id is missing or all other fields are empty\n",
    "        # Remove rows without id first\n",
    "        missing_id_mask = self.df['id'].isna() | (self.df['id'].astype(str).str.strip() == '')\n",
    "        num_missing = missing_id_mask.sum()\n",
    "        print(f\"\\nFound {num_missing} row(s) with missing id\")\n",
    "        self.df = self.df.loc[~missing_id_mask]\n",
    "\n",
    "        # Remove rows where ALL other fields are empty\n",
    "        critical_cols = [col for col in self.df.columns if col != 'id']\n",
    "        all_empty_mask = pd.Series(True, index=self.df.index)\n",
    "\n",
    "        for col in critical_cols:\n",
    "            if self.df[col].dtype in [int, float]:\n",
    "                col_has_value = ~self.df[col].isna() & (self.df[col] != 0)\n",
    "            else:\n",
    "                col_has_value = ~self.df[col].astype(str).str.strip().eq('') & ~self.df[col].isna()\n",
    "            all_empty_mask &= ~col_has_value  # Keep True only if ALL fields are empty\n",
    "\n",
    "        num_empty_rows = all_empty_mask.sum()\n",
    "        print(f\"Found {num_empty_rows} row(s) where all fields are empty\")\n",
    "        self.df = self.df.loc[~all_empty_mask]\n",
    "        print(\"Removing empty rows...\")\n",
    "        print(f\"Number of rows left after removing empty rows = {len(self.df)}\")\n",
    "\n",
    "    def fill_missing(self): # method to fill missing fields except for id\n",
    "        for col in self.df.columns:\n",
    "            if col != 'id':\n",
    "                if self.df[col].dtype.kind in ['f', 'i'] :\n",
    "                    # self.df[col] = self.df[col].fillna(0)\n",
    "                    pass\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].fillna('')\n",
    "        print(\"\\nFilling missing fields...\")\n",
    "    def clean_zip_code(self):\n",
    "        if 'zip_code' in self.df.columns:\n",
    "            self.df = clean_numeric_column(self.df, 'zip_code', as_int=True)\n",
    "            print(\"Cleaning zip code field...\")\n",
    "\n",
    "    def save_to_csv(self, output_path='../data/cleaned/cleaned_property_data.csv'): # method to create the output file, update file path <---\n",
    "        self.df.to_csv(output_path, index=False)\n",
    "        print(\"\\nSaving cleaned output as csv ...\")"
   ],
   "id": "8e8b43cfbbdd8f79",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:50:58.165183Z",
     "start_time": "2025-11-13T10:50:50.410326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dp = DataProcessing(file_path='../Bryan/sample_data_copy/properties.csv')  # adjust path\n",
    "dp.process_data()\n",
    "\n",
    "for column in dp.df.columns:\n",
    "    validate_and_report(dp.df, column)\n",
    "\n",
    "dp.save_to_csv('../Bryan/cleaned_properties.csv')"
   ],
   "id": "93a88b4f94d17b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected separator: ','\n",
      "\n",
      "Before any cleaning:\n",
      "id                                  int64\n",
      "price                             float64\n",
      "property_type                      object\n",
      "subproperty_type                   object\n",
      "region                             object\n",
      "province                           object\n",
      "locality                           object\n",
      "zip_code                            int64\n",
      "latitude                          float64\n",
      "longitude                         float64\n",
      "construction_year                 float64\n",
      "total_area_sqm                    float64\n",
      "surface_land_sqm                  float64\n",
      "nbr_frontages                     float64\n",
      "nbr_bedrooms                      float64\n",
      "equipped_kitchen                   object\n",
      "fl_furnished                        int64\n",
      "fl_open_fire                        int64\n",
      "fl_terrace                          int64\n",
      "terrace_sqm                       float64\n",
      "fl_garden                           int64\n",
      "garden_sqm                        float64\n",
      "fl_swimming_pool                    int64\n",
      "fl_floodzone                        int64\n",
      "state_building                     object\n",
      "primary_energy_consumption_sqm    float64\n",
      "epc                                object\n",
      "heating_type                       object\n",
      "fl_double_glazing                   int64\n",
      "cadastral_income                  float64\n",
      "dtype: object \n",
      "\n",
      "         id     price property_type subproperty_type            region  \\\n",
      "0  34221000  225000.0     APARTMENT        APARTMENT          Flanders   \n",
      "1   2104000  449000.0         HOUSE            HOUSE          Flanders   \n",
      "2  34036000  335000.0     APARTMENT        APARTMENT  Brussels-Capital   \n",
      "3  58496000  501000.0         HOUSE            HOUSE          Flanders   \n",
      "4  48727000  982700.0     APARTMENT           DUPLEX          Wallonia   \n",
      "\n",
      "          province  locality  zip_code   latitude  longitude  ...  fl_garden  \\\n",
      "0          Antwerp   Antwerp      2050  51.217172   4.379982  ...          0   \n",
      "1    East Flanders      Gent      9185  51.174944   3.845248  ...          0   \n",
      "2         Brussels  Brussels      1070  50.842043   4.334543  ...          0   \n",
      "3          Antwerp  Turnhout      2275  51.238312   4.817192  ...          0   \n",
      "4  Walloon Brabant  Nivelles      1410        NaN        NaN  ...          1   \n",
      "\n",
      "   garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0         0.0                 0             0         MISSING   \n",
      "1         0.0                 0             0         MISSING   \n",
      "2         0.0                 0             1          AS_NEW   \n",
      "3         0.0                 0             1         MISSING   \n",
      "4       142.0                 0             0          AS_NEW   \n",
      "\n",
      "  primary_energy_consumption_sqm      epc  heating_type  fl_double_glazing  \\\n",
      "0                          231.0        C           GAS                  1   \n",
      "1                          221.0        C       MISSING                  1   \n",
      "2                            NaN  MISSING           GAS                  0   \n",
      "3                           99.0        A       MISSING                  0   \n",
      "4                           19.0       A+           GAS                  0   \n",
      "\n",
      "   cadastral_income  \n",
      "0             922.0  \n",
      "1             406.0  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Number of rows raw data loaded: 75511\n",
      "Cleaning price fields...\n",
      "  Cleaned 'total_area_sqm': 7615 values converted to null due to invalid data\n",
      "  Cleaned 'terrace_sqm': 13140 values converted to null due to invalid data\n",
      "  Cleaned 'garden_sqm': 2939 values converted to null due to invalid data\n",
      "Cleaning area fields...\n",
      "Converting Yes/No columns to 1/0 integers...\n",
      "Cleaning other numeric fields...\n",
      "\n",
      "No duplicate rows found.\n",
      "Removing duplicates...\n",
      "Number of rows left after removing duplicates = 75511\n",
      "\n",
      "Found 0 row(s) with missing id\n",
      "Found 0 row(s) where all fields are empty\n",
      "Removing empty rows...\n",
      "Number of rows left after removing empty rows = 75511\n",
      "\n",
      "Filling missing fields...\n",
      "\n",
      "--- Statistics for 'id' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 79485000\n",
      "  Mean: 39732354.60\n",
      "  Median: 39722000.00\n",
      "\n",
      "--- Statistics for 'price' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: Int64\n",
      "  Min: 76000\n",
      "  Max: 22500000\n",
      "  Mean: 422770.85\n",
      "  Median: 329000.00\n",
      "  ⚠️  Potential outliers (IQR method): 5800 (7.7%)\n",
      "\n",
      "--- Statistics for 'property_type' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'subproperty_type' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'region' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'province' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'locality' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'zip_code' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 1000\n",
      "  Max: 9992\n",
      "  Mean: 5144.61\n",
      "  Median: 4683.00\n",
      "\n",
      "--- Statistics for 'latitude' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 61413 (81.3%)\n",
      "  Null values: 14098 (18.7%)\n",
      "  Data type: float64\n",
      "  Min: 25.7616798\n",
      "  Max: 52.4342442\n",
      "  Mean: 50.89\n",
      "  Median: 50.90\n",
      "  ⚠️  Potential outliers (IQR method): 1302 (2.1%)\n",
      "\n",
      "--- Statistics for 'longitude' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 61413 (81.3%)\n",
      "  Null values: 14098 (18.7%)\n",
      "  Data type: float64\n",
      "  Min: -80.1917902\n",
      "  Max: 6.3850484\n",
      "  Mean: 4.33\n",
      "  Median: 4.38\n",
      "  ⚠️  Potential outliers (IQR method): 2 (0.0%)\n",
      "\n",
      "--- Statistics for 'construction_year' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 42120 (55.8%)\n",
      "  Null values: 33391 (44.2%)\n",
      "  Data type: float64\n",
      "  Min: 1753.0\n",
      "  Max: 2024.0\n",
      "  Mean: 1984.41\n",
      "  Median: 1994.00\n",
      "  ⚠️  Potential outliers (IQR method): 711 (1.7%)\n",
      "\n",
      "--- Statistics for 'total_area_sqm' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 67896 (89.9%)\n",
      "  Null values: 7615 (10.1%)\n",
      "  Data type: Int64\n",
      "  Min: 3\n",
      "  Max: 88140\n",
      "  Mean: 163.67\n",
      "  Median: 127.00\n",
      "  ⚠️  Potential outliers (IQR method): 3995 (5.9%)\n",
      "\n",
      "--- Statistics for 'surface_land_sqm' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 39255 (52.0%)\n",
      "  Null values: 36256 (48.0%)\n",
      "  Data type: float64\n",
      "  Min: 0.0\n",
      "  Max: 950774.0\n",
      "  Mean: 1157.09\n",
      "  Median: 362.00\n",
      "  ⚠️  Potential outliers (IQR method): 3534 (9.0%)\n",
      "\n",
      "--- Statistics for 'nbr_frontages' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 49165 (65.1%)\n",
      "  Null values: 26346 (34.9%)\n",
      "  Data type: float64\n",
      "  Min: 1.0\n",
      "  Max: 47.0\n",
      "  Mean: 2.80\n",
      "  Median: 3.00\n",
      "  ⚠️  Potential outliers (IQR method): 17 (0.0%)\n",
      "\n",
      "--- Statistics for 'nbr_bedrooms' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: float64\n",
      "  Min: 0.0\n",
      "  Max: 200.0\n",
      "  Mean: 2.79\n",
      "  Median: 3.00\n",
      "  ⚠️  Potential outliers (IQR method): 8376 (11.1%)\n",
      "\n",
      "--- Statistics for 'equipped_kitchen' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 0\n",
      "  Mean: 0.00\n",
      "  Median: 0.00\n",
      "\n",
      "--- Statistics for 'fl_furnished' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 0\n",
      "  Mean: 0.00\n",
      "  Median: 0.00\n",
      "\n",
      "--- Statistics for 'fl_open_fire' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 0\n",
      "  Mean: 0.00\n",
      "  Median: 0.00\n",
      "\n",
      "--- Statistics for 'fl_terrace' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 1\n",
      "  Mean: 0.59\n",
      "  Median: 1.00\n",
      "\n",
      "--- Statistics for 'terrace_sqm' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 62371 (82.6%)\n",
      "  Null values: 13140 (17.4%)\n",
      "  Data type: Int64\n",
      "  Min: 0\n",
      "  Max: 3466\n",
      "  Mean: 11.58\n",
      "  Median: 1.00\n",
      "  ⚠️  Potential outliers (IQR method): 4423 (7.1%)\n",
      "\n",
      "--- Statistics for 'fl_garden' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 1\n",
      "  Mean: 0.22\n",
      "  Median: 0.00\n",
      "  ⚠️  Potential outliers (IQR method): 16483 (21.8%)\n",
      "\n",
      "--- Statistics for 'garden_sqm' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 72572 (96.1%)\n",
      "  Null values: 2939 (3.9%)\n",
      "  Data type: Int64\n",
      "  Min: 0\n",
      "  Max: 150000\n",
      "  Mean: 115.64\n",
      "  Median: 0.00\n",
      "  ⚠️  Potential outliers (IQR method): 13544 (18.7%)\n",
      "\n",
      "--- Statistics for 'fl_swimming_pool' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 0\n",
      "  Mean: 0.00\n",
      "  Median: 0.00\n",
      "\n",
      "--- Statistics for 'fl_floodzone' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 1\n",
      "  Mean: 0.54\n",
      "  Median: 1.00\n",
      "\n",
      "--- Statistics for 'state_building' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'primary_energy_consumption_sqm' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 48944 (64.8%)\n",
      "  Null values: 26567 (35.2%)\n",
      "  Data type: float64\n",
      "  Min: -140.0\n",
      "  Max: 20231122.0\n",
      "  Mean: 1688.75\n",
      "  Median: 242.00\n",
      "  ⚠️  Potential outliers (IQR method): 1661 (3.4%)\n",
      "\n",
      "--- Statistics for 'epc' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'heating_type' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: object\n",
      "\n",
      "--- Statistics for 'fl_double_glazing' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 75511 (100.0%)\n",
      "  Null values: 0 (0.0%)\n",
      "  Data type: int64\n",
      "  Min: 0\n",
      "  Max: 1\n",
      "  Mean: 0.68\n",
      "  Median: 1.00\n",
      "\n",
      "--- Statistics for 'cadastral_income' ---\n",
      "  Total rows: 75511\n",
      "  Non-null values: 30544 (40.4%)\n",
      "  Null values: 44967 (59.6%)\n",
      "  Data type: float64\n",
      "  Min: 1.0\n",
      "  Max: 17001700.0\n",
      "  Mean: 1885.94\n",
      "  Median: 850.00\n",
      "  ⚠️  Potential outliers (IQR method): 2230 (7.3%)\n",
      "\n",
      "Saving cleaned output as csv ...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:50:58.385434Z",
     "start_time": "2025-11-13T10:50:58.382343Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e5d2969e9d25555",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
